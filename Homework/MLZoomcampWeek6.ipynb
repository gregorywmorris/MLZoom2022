{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gregorywmorris/MLZoom2022/blob/main/Homework/MLZoomcampWeek6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HOMEWORK**  \n",
        "\n",
        "The goal of this homework is to create a regression model for predicting housing prices (column 'median_house_value').  \n",
        "\n",
        "In this homework we'll again use the California Housing Prices dataset - the same one we used in homework 2 and 3.\n",
        "\n",
        "You can take it from [Kaggle](https://www.kaggle.com/datasets/camnugent/california-housing-prices) or download using wget link mentioned below:\n",
        "\n",
        "```\n",
        "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-JrenrSGmAeg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLosiCNJUjDM"
      },
      "outputs": [],
      "source": [
        "#@ IMPORTING LIBRARIES AND DEPENDENCIES:\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import export_text\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ DOWNLOADING THE DATASET: UNCOMMENT BELOW:\n",
        "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv"
      ],
      "metadata": {
        "id": "4Psk224nnyIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ READING DATASET:\n",
        "PATH = \"./housing.csv\"\n",
        "select_cols = [\"longitude\", \"latitude\", \"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"population\", \"households\", \n",
        "               \"median_income\", \"median_house_value\", \"ocean_proximity\"]\n",
        "df = pd.read_csv(PATH, usecols=select_cols)\n",
        "df.total_bedrooms = df.total_bedrooms.fillna(0)"
      ],
      "metadata": {
        "id": "492Hn6-3n08G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Apply the log transform to `median_house_value`. \n",
        "- Do train/validation/test split with 60%/20%/20% distribution.\n",
        "- Use the `train_test_split` function and set the `random_state parameter` to 1."
      ],
      "metadata": {
        "id": "OqXppJ_Ro0H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ SPLITTING THE DATASET FOR TRAINING AND TEST:\n"
      ],
      "metadata": {
        "id": "W1MmdcRDpHS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We will use `DictVectorizer` to turn train and validation into matrices."
      ],
      "metadata": {
        "id": "5VKq8FX7qIVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ IMPLEMENTATION OF DICTVECTORIZER:\n"
      ],
      "metadata": {
        "id": "WnfFrWe9qtuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**\n",
        "\n",
        "Let's train a decision tree regressor to predict the `median_house_value` variable.\n",
        "\n",
        "Train a model with `max_depth=1`."
      ],
      "metadata": {
        "id": "qvxmhaD5hmAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ TRAINING THE REGRESSION MODEL:\n"
      ],
      "metadata": {
        "id": "cqBcSbpIq7kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INSPECTION:\n"
      ],
      "metadata": {
        "id": "sLAnqRwuikqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Which feature is used for splitting the data?\n",
        "\n",
        "- Answer:"
      ],
      "metadata": {
        "id": "JNBm-qeRp6aZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**\n",
        "\n",
        "Train a random forest model with these parameters:\n",
        "\n",
        "- `n_estimators=10`  \n",
        "- `random_state=1`  \n",
        "- `n_jobs=-1` (optional-to make training faster)"
      ],
      "metadata": {
        "id": "Xhnbdy-CqQoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ TRAINING RANDOM FOREST MODEL:\n"
      ],
      "metadata": {
        "id": "2w-YSGYMisFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CALCULATING MEAN SQUARED ERROR:\n"
      ],
      "metadata": {
        "id": "jCxUAO2Rq1Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What's the RMSE of this model on validation?\n",
        "\n",
        "- Answer: "
      ],
      "metadata": {
        "id": "jfcDllHxrTqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**\n",
        "\n",
        "Now, let's experiment with the `n_estimators` parameter.\n",
        "\n",
        "- Try different values of this parameter from 10 to 200 with step 10.\n",
        "- Set `random_state` to 1.\n",
        "- Evaluate the model on the validation dataset."
      ],
      "metadata": {
        "id": "Y7K69bFSrg_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ TRAINING THE RANDOM FOREST MODEL:\n"
      ],
      "metadata": {
        "id": "-oUFCQwOrQNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ INSPECTING THE RMSE SCORES:\n"
      ],
      "metadata": {
        "id": "3J-wFLh4s8Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- After which value of `n_estimators` does RMSE stop improving?\n",
        "\n",
        "- Answer: "
      ],
      "metadata": {
        "id": "NAXZcW3AuC-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4**\n",
        "\n",
        "Let's select the best `max_depth`:\n",
        "\n",
        "- Try different values of `max_depth`: [10, 15, 20, 25].\n",
        "- For each of these values, try different values of n_estimators from 10 till 200 (with step 10).\n",
        "- Fix the random seed: `random_state=1`."
      ],
      "metadata": {
        "id": "CYhRv3kEvWjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ TRAINING THE MODEL WITH DEPTH:\n"
      ],
      "metadata": {
        "id": "fO9TackKvKcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What's the best `max_depth`:\n",
        "\n",
        "- Answer:"
      ],
      "metadata": {
        "id": "eCRCaKlSwp7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5**\n",
        "\n",
        "We can extract feature importance information from tree-based models.\n",
        "\n",
        "At each step of the decision tree learning algorith, it finds the best split. When doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. This gain is quite useful in understanding what are the imporatant features for tree-based models.\n",
        "\n",
        "In Scikit-Learn, tree-based models contain this information in the `feature_importances_` field.\n",
        "\n",
        "For this homework question, we'll find the most important feature:\n",
        "\n",
        "Train the model with these parametes:\n",
        "- `n_estimators=10`,\n",
        "- `max_depth=20`,\n",
        "- `random_state=1`,\n",
        "- `n_jobs=-1` (optional)\n",
        "\n",
        "Get the feature importance information from this model"
      ],
      "metadata": {
        "id": "BDLbx3N5xAoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ TRAINING THE RANDOM FOREST MODEL:\n"
      ],
      "metadata": {
        "id": "UICqST2Qwhbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What's the most important feature?\n",
        "\n",
        "- Answer:"
      ],
      "metadata": {
        "id": "kSCqlx9jye1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6**\n",
        "\n",
        "Now let's train an XGBoost model! For this question, we'll tune the eta parameter:\n",
        "\n",
        "- Install XGBoost.\n",
        "- Create DMatrix for train and validation\n",
        "- Create a watchlist\n",
        "- Train a model with these parameters for 100 rounds:\n",
        "\n",
        "```\n",
        "xgb_params = {  \n",
        "    'eta': 0.3,  \n",
        "    'max_depth': 6,  \n",
        "    'min_child_weight': 1,  \n",
        "\n",
        "    'objective': 'reg:squarederror',\n",
        "    'nthread': 8,\n",
        "\n",
        "    'seed': 1,\n",
        "    'verbosity': 1,\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "K5KEdiTMzPaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ CREATING THE DMARTIX:\n",
        "features = dv.feature_names_\n",
        "\n",
        "regex = re.compile(r\"<\", re.IGNORECASE)\n",
        "features = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in features]\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
        "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)"
      ],
      "metadata": {
        "id": "TUP0uoL5yZTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRRzLznP-Z-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now, change eta first to 0.1 and then to 0.01."
      ],
      "metadata": {
        "id": "3RmcQ1BQ64X-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Which eta leads to the best RMSE score on the validation dataset?\n",
        "\n",
        "- Answer:"
      ],
      "metadata": {
        "id": "Yl6Xn6Zb76iH"
      }
    }
  ]
}